{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from NeuralNetwork import loss, activation, layer, network\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR Gate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "\n",
    "Y = np.array([[0], [1],\n",
    "              [1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network.Sequential()\n",
    "model.add_layer(layer.Dense(n_neurons=3, name='Layer_1', freeze_weights=False, weights=np.array([[0.1, 0.2, 0.3],\n",
    "                                                                                                     [0.6, 0.4, 0.7]]),\n",
    "                                bias=np.array([[0, 0, 0]])))\n",
    "\n",
    "model.add_layer(activation.Sigmoid(name='Activation_1'))\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=1, name='Layer_2', freeze_weights=False, weights=np.array([[0.1],\n",
    "                                                                                                     [0.4],\n",
    "                                                                                                     [0.9]]),\n",
    "                                bias = np.array([[0]])))\n",
    "\n",
    "model.add_layer(activation.Sigmoid(name='Activation_2'))\n",
    "\n",
    "print(model)\n",
    "model.compile(loss=loss.MSE(), inputs=X, target=Y, batch=4)\n",
    "print(model)\n",
    "\n",
    "model.train(epochs=5000)\n",
    "\n",
    "pred_val = model.predict(inputs=X)\n",
    "print(pred_val)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantile Regression Prediction Interval\n",
    "Prediction Interval at 0.977 - 0.023 ~ 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_predictable(x):\n",
    "    return x+np.sin(np.pi*x/2)\n",
    "\n",
    "\n",
    "def f(x, std=0.2):\n",
    "    return f_predictable(x)+np.random.randn(len(x))*std\n",
    "\n",
    "\n",
    "def get_data(num, start=0, end=4):\n",
    "        x = np.sort(np.random.rand(num)*(end-start)+start)\n",
    "        y = f(x)\n",
    "        return x.reshape(-1, 1), y\n",
    "\n",
    "x_train, y_train = get_data(num=20000)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "x_test, y_test = get_data(num=1000)\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_upper = network.Sequential()\n",
    "\n",
    "model_upper.add_layer(layer.Dense(n_neurons=100, name='Layer_1', freeze_weights=False, lr=0.01))\n",
    "\n",
    "model_upper.add_layer(activation.ReLU(name='Activation_1'))\n",
    "\n",
    "model_upper.add_layer(layer.Dense(n_neurons=100, name='Layer_2', freeze_weights=False, lr=0.01))\n",
    "\n",
    "model_upper.add_layer(activation.ReLU(name='Activation_2'))\n",
    "\n",
    "model_upper.add_layer(layer.Dense(n_neurons=100, name='Layer_3', freeze_weights=False, lr=0.01))\n",
    "\n",
    "model_upper.add_layer(activation.ReLU(name='Activation_3'))\n",
    "\n",
    "model_upper.add_layer(layer.Dense(n_neurons=1, name='Layer_4', freeze_weights=False, lr=0.01))\n",
    "\n",
    "model_upper.compile(loss=loss.Quantile(quantile=0.977), inputs=x_train, target=y_train, batch=24)\n",
    "\n",
    "model_upper.train(epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lower = network.Sequential()\n",
    "\n",
    "model_lower.add_layer(layer.Dense(n_neurons=100, name='Layer_1', freeze_weights=False, lr=0.01))\n",
    "\n",
    "model_lower.add_layer(activation.ReLU(name='Activation_1'))\n",
    "\n",
    "model_lower.add_layer(layer.Dense(n_neurons=100, name='Layer_2', freeze_weights=False, lr=0.01))\n",
    "\n",
    "model_lower.add_layer(activation.ReLU(name='Activation_2'))\n",
    "\n",
    "model_lower.add_layer(layer.Dense(n_neurons=100, name='Layer_3', freeze_weights=False, lr=0.01))\n",
    "\n",
    "model_lower.add_layer(activation.ReLU(name='Activation_3'))\n",
    "\n",
    "model_lower.add_layer(layer.Dense(n_neurons=1, name='Layer_4', freeze_weights=False, lr=0.01))\n",
    "\n",
    "model_lower.compile(loss=loss.Quantile(quantile=0.023), inputs=x_train, target=y_train, batch=24)\n",
    "\n",
    "model_lower.train(epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x_train.reshape(-1), y=y_train.reshape(-1),\n",
    "                    mode='markers',\n",
    "                    name='Original Data'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x_test.reshape(-1), y=model_upper.predict(x_test).reshape(-1),\n",
    "                    mode='lines',\n",
    "                    name='Upper Bound'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x_test.reshape(-1), y=model_lower.predict(x_test).reshape(-1),\n",
    "                    mode='lines',\n",
    "                    name='Lower Bound'))\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification\n",
    "Multi Class Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "cat_images = np.random.randn(700, 2) + np.array([0, -3])\n",
    "mouse_images = np.random.randn(700, 2) + np.array([3, 3])\n",
    "dog_images = np.random.randn(700, 2) + np.array([-3, 3])\n",
    "\n",
    "feature_set = np.vstack([cat_images, mouse_images, dog_images])\n",
    "labels = np.array([0]*700 + [1]*700 + [2]*700)\n",
    "\n",
    "one_hot_labels = np.zeros((2100, 3))\n",
    "\n",
    "for i in range(2100):\n",
    "    one_hot_labels[i, labels[i]] = 1\n",
    "    \n",
    "dataset = pd.DataFrame(np.hstack([feature_set, labels.reshape(-1, 1)]), columns=['X','Y','Labels'])\n",
    "dataset.Labels = dataset.Labels.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(dataset, x=\"X\", y=\"Y\", color=\"Labels\", hover_data=[dataset.index])\n",
    "fig.update_layout(width=1000, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = network.Sequential()\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=4, name='Layer_1', freeze_weights=False, lr=0.001))\n",
    "\n",
    "model.add_layer(activation.Sigmoid(name='Activation_1'))\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=3, name='Layer_2', freeze_weights=False, lr=0.001))\n",
    "\n",
    "model.add_layer(activation.Sigmoid(name='Activation_2'))\n",
    "\n",
    "model.compile(loss=loss.CrossEntropy(), inputs=feature_set, target=one_hot_labels, batch=16)\n",
    "\n",
    "model.train(epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = np.argmax(model.predict(feature_set), axis=1)\n",
    "np.where((pred_val == labels)==False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SquaredHinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = -1*np.ones((2100, 3))\n",
    "\n",
    "for i in range(2100):\n",
    "    one_hot_labels[i, labels[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = network.Sequential()\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=4, name='Layer_1', freeze_weights=False, lr=0.001))\n",
    "\n",
    "model.add_layer(activation.Sigmoid(name='Activation_1'))\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=3, name='Layer_2', freeze_weights=False, lr=0.001))\n",
    "\n",
    "model.add_layer(activation.Tanh(name='Activation_2'))\n",
    "\n",
    "model.compile(loss=loss.SquaredHinge(), inputs=feature_set, target=one_hot_labels, batch=16)\n",
    "\n",
    "model.train(epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = np.argmax(model.predict(feature_set), axis=1)\n",
    "np.where((pred_val == labels)==False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification\n",
    "Multi Label Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "cat_images = np.random.randn(700, 2) + np.array([0, -3])\n",
    "mouse_images = np.random.randn(700, 2) + np.array([3, 3])\n",
    "dog_images = np.random.randn(700, 2) + np.array([-3, 3])\n",
    "\n",
    "feature_set = np.vstack([cat_images, mouse_images, dog_images])\n",
    "labels = np.array([0]*700 + [1]*700 + [1]*700)\n",
    "\n",
    "one_hot_labels = np.zeros((2100, 3))\n",
    "\n",
    "for i in range(700):\n",
    "    one_hot_labels[i, labels[i]] = 1\n",
    "    \n",
    "for i in range(700, 2100):\n",
    "    one_hot_labels[i,1:] = 1\n",
    "    \n",
    "dataset = pd.DataFrame(np.hstack([feature_set, labels.reshape(-1, 1)]), columns=['X','Y','Labels'])\n",
    "dataset.Labels = dataset.Labels.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(dataset, x=\"X\", y=\"Y\", color=\"Labels\", hover_data=[dataset.index])\n",
    "fig.update_layout(width=1000, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network.Sequential()\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=4, name='Layer_1', freeze_weights=False, lr=0.001))\n",
    "\n",
    "model.add_layer(activation.Sigmoid(name='Activation_1'))\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=3, name='Layer_2', freeze_weights=False, lr=0.001))\n",
    "\n",
    "model.add_layer(activation.Sigmoid(name='Activation_2'))\n",
    "\n",
    "model.compile(loss=loss.CrossEntropy(), inputs=feature_set, target=one_hot_labels, batch=16)\n",
    "\n",
    "model.train(epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_val = np.where(model.predict(feature_set)>0.5, 1, 0)\n",
    "np.where((pred_val == one_hot_labels)==False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SquaredHinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = -np.ones((2100, 3))\n",
    "\n",
    "for i in range(700):\n",
    "    one_hot_labels[i, labels[i]] = 1\n",
    "    \n",
    "for i in range(700, 2100):\n",
    "    one_hot_labels[i,1:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network.Sequential()\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=4, name='Layer_1', freeze_weights=False, lr=0.001))\n",
    "\n",
    "model.add_layer(activation.Sigmoid(name='Activation_1'))\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=3, name='Layer_2', freeze_weights=False, lr=0.001))\n",
    "\n",
    "model.add_layer(activation.Tanh(name='Activation_2'))\n",
    "\n",
    "model.compile(loss=loss.SquaredHinge(), inputs=feature_set, target=one_hot_labels, batch=16)\n",
    "\n",
    "model.train(epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = np.where(model.predict(feature_set)>0, 1, -1)\n",
    "np.where((pred_val == one_hot_labels)==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from NeuralNetwork import loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7 15 11 ... 10  6 17]\n",
      " [17 19 18 ... 14 14 13]\n",
      " [16  8  8 ... 15  2  4]\n",
      " ...\n",
      " [19  4  4 ...  5 18 10]\n",
      " [18 17 11 ... 19 12  2]\n",
      " [ 9  1  3 ...  8  4  2]]\n",
      "\n",
      "[[ 7 16 13 ... 19  2  7]\n",
      " [13 14  8 ... 12 16 13]\n",
      " [12 11 10 ... 17 19  5]\n",
      " ...\n",
      " [ 9  7  7 ...  6  3 14]\n",
      " [ 6 10 11 ...  7 16  3]\n",
      " [15 14  8 ...  4 16  1]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "target = np.random.randint(low=1,high=20, size=(10000,10000))\n",
    "print(target)\n",
    "\n",
    "print()\n",
    "\n",
    "pred = np.random.randint(low=1,high=20, size=(10000,10000))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = loss.MSE()\n",
    "mae = loss.MAE()\n",
    "hubber = loss.Hubber()\n",
    "logcosh = loss.LogCosh()\n",
    "quantile = loss.Quantile()\n",
    "crossentropy = loss.CrossEntropy()\n",
    "squaredhinge = loss.SquaredHinge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289 ms ± 53 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "409 ms ± 40.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "250 ms ± 30.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "533 ms ± 105 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "1.37 s ± 30.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "861 ms ± 32.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "2.45 s ± 27.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.5 s ± 43.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "1.1 s ± 7.05 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "476 ms ± 45.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thinagar\\Documents\\Python Scripts\\DeepLearning\\NeuralNetwork\\loss.py:214: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = -self.target * (np.log(self.pred_val)) - (1 - self.target) * np.log(1 - self.pred_val)\n",
      "C:\\Users\\Thinagar\\Documents\\Python Scripts\\DeepLearning\\NeuralNetwork\\loss.py:214: RuntimeWarning: invalid value encountered in log\n",
      "  diff = -self.target * (np.log(self.pred_val)) - (1 - self.target) * np.log(1 - self.pred_val)\n",
      "C:\\Users\\Thinagar\\Documents\\Python Scripts\\DeepLearning\\NeuralNetwork\\loss.py:214: RuntimeWarning: invalid value encountered in multiply\n",
      "  diff = -self.target * (np.log(self.pred_val)) - (1 - self.target) * np.log(1 - self.pred_val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.94 s ± 62.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thinagar\\Documents\\Python Scripts\\DeepLearning\\NeuralNetwork\\loss.py:226: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  + ((1 - self.target) / (1 - self.pred_val))\n",
      "C:\\Users\\Thinagar\\Documents\\Python Scripts\\DeepLearning\\NeuralNetwork\\loss.py:226: RuntimeWarning: invalid value encountered in true_divide\n",
      "  + ((1 - self.target) / (1 - self.pred_val))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14 s ± 33.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "526 ms ± 42.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "774 ms ± 41.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mse.forward(target=target, pred_val=pred)\n",
    "%timeit mse.backward()\n",
    "print()\n",
    "%timeit mae.forward(target=target, pred_val=pred)\n",
    "%timeit mae.backward()\n",
    "print()\n",
    "%timeit hubber.forward(target=target, pred_val=pred)\n",
    "%timeit hubber.backward()\n",
    "print()\n",
    "%timeit logcosh.forward(target=target, pred_val=pred)\n",
    "%timeit logcosh.backward()\n",
    "print()\n",
    "%timeit quantile.forward(target=target, pred_val=pred)\n",
    "%timeit quantile.backward()\n",
    "print()\n",
    "%timeit crossentropy.forward(target=target, pred_val=pred)\n",
    "%timeit crossentropy.backward()\n",
    "print()\n",
    "%timeit squaredhinge.forward(target=target, pred_val=pred)\n",
    "%timeit squaredhinge.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
