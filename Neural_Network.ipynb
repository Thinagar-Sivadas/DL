{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from NeuralNetwork import loss, activation, layer, network, optimiser\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling XOR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n",
      "\n",
      "Output:\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "print(f'Input:\\n{X}', end='\\n'*2)\n",
    "\n",
    "Y = np.array([[0], [1],\n",
    "              [1], [0]])\n",
    "print(f'Output:\\n{X}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "Layer_Name            Type                  Output Shape          Param                 \n",
      "========================================================================================\n",
      "Layer_1               Dense                 (None, 3)             9                     \n",
      "========================================================================================\n",
      "Activation_1          Sigmoid               (None, 3)             None                  \n",
      "========================================================================================\n",
      "Layer_2               Dense                 (None, 1)             4                     \n",
      "========================================================================================\n",
      "Activation_2          Sigmoid               (None, 1)             None                  \n",
      "========================================================================================\n",
      "Total Params: 13\n",
      "Trainable params:: 13\n",
      "Non-Trainable params: 0\n",
      "\n",
      "Epoch:20/500 ------------------------ Loss:0.12729\n",
      "Epoch:40/500 ------------------------ Loss:0.124769\n",
      "Epoch:60/500 ------------------------ Loss:0.124266\n",
      "Epoch:80/500 ------------------------ Loss:0.122953\n",
      "Epoch:100/500 ------------------------ Loss:0.119639\n",
      "Epoch:120/500 ------------------------ Loss:0.112353\n",
      "Epoch:140/500 ------------------------ Loss:0.099507\n",
      "Epoch:160/500 ------------------------ Loss:0.084228\n",
      "Epoch:180/500 ------------------------ Loss:0.066019\n",
      "Epoch:200/500 ------------------------ Loss:0.040367\n",
      "Epoch:220/500 ------------------------ Loss:0.019252\n",
      "Epoch:240/500 ------------------------ Loss:0.00988\n",
      "Epoch:260/500 ------------------------ Loss:0.006147\n",
      "Epoch:280/500 ------------------------ Loss:0.004375\n",
      "Epoch:300/500 ------------------------ Loss:0.003372\n",
      "Epoch:320/500 ------------------------ Loss:0.002731\n",
      "Epoch:340/500 ------------------------ Loss:0.002288\n",
      "Epoch:360/500 ------------------------ Loss:0.001963\n",
      "Epoch:380/500 ------------------------ Loss:0.001716\n",
      "Epoch:400/500 ------------------------ Loss:0.001521\n",
      "Epoch:420/500 ------------------------ Loss:0.001365\n",
      "Epoch:440/500 ------------------------ Loss:0.001236\n",
      "Epoch:460/500 ------------------------ Loss:0.001129\n",
      "Epoch:480/500 ------------------------ Loss:0.001038\n",
      "Epoch:500/500 ------------------------ Loss:0.00096\n",
      "\n",
      "--------------------Training Completed--------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Cost",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500
         ],
         "y": [
          0.144559,
          0.141042,
          0.135283,
          0.129363,
          0.125583,
          0.125146,
          0.127344,
          0.130305,
          0.132351,
          0.132669,
          0.131305,
          0.128938,
          0.126578,
          0.125143,
          0.125012,
          0.125886,
          0.127056,
          0.127849,
          0.127914,
          0.12729,
          0.12631,
          0.125409,
          0.124927,
          0.124953,
          0.125332,
          0.125781,
          0.126048,
          0.126016,
          0.125724,
          0.125321,
          0.124983,
          0.124824,
          0.124862,
          0.12502,
          0.125183,
          0.125259,
          0.125212,
          0.125071,
          0.1249,
          0.124769,
          0.124715,
          0.124734,
          0.124791,
          0.124839,
          0.124844,
          0.1248,
          0.124722,
          0.12464,
          0.12458,
          0.124551,
          0.124548,
          0.124554,
          0.12455,
          0.124525,
          0.124481,
          0.124425,
          0.12437,
          0.124325,
          0.124292,
          0.124266,
          0.124239,
          0.124205,
          0.124159,
          0.124105,
          0.124047,
          0.123989,
          0.123935,
          0.123882,
          0.123829,
          0.123772,
          0.123709,
          0.123638,
          0.123563,
          0.123484,
          0.123404,
          0.123321,
          0.123237,
          0.123148,
          0.123053,
          0.122953,
          0.122846,
          0.122734,
          0.122618,
          0.122497,
          0.122371,
          0.12224,
          0.122102,
          0.121958,
          0.121806,
          0.121647,
          0.121481,
          0.121309,
          0.121129,
          0.120942,
          0.120747,
          0.120543,
          0.120331,
          0.120109,
          0.119879,
          0.119639,
          0.11939,
          0.119131,
          0.118861,
          0.118581,
          0.118289,
          0.117986,
          0.117672,
          0.117345,
          0.117006,
          0.116654,
          0.116289,
          0.11591,
          0.115517,
          0.11511,
          0.114689,
          0.114252,
          0.1138,
          0.113334,
          0.112851,
          0.112353,
          0.111839,
          0.111309,
          0.110764,
          0.110203,
          0.109627,
          0.109035,
          0.10843,
          0.107809,
          0.107175,
          0.106528,
          0.105869,
          0.105198,
          0.104516,
          0.103824,
          0.103123,
          0.102413,
          0.101696,
          0.100972,
          0.100242,
          0.099507,
          0.098767,
          0.098023,
          0.097275,
          0.096525,
          0.095772,
          0.095017,
          0.09426,
          0.0935,
          0.09274,
          0.091977,
          0.091213,
          0.090447,
          0.08968,
          0.08891,
          0.088138,
          0.087363,
          0.086585,
          0.085803,
          0.085018,
          0.084228,
          0.083432,
          0.082631,
          0.081822,
          0.081007,
          0.080182,
          0.079348,
          0.078503,
          0.077646,
          0.076777,
          0.075893,
          0.074994,
          0.074079,
          0.073145,
          0.072193,
          0.07122,
          0.070226,
          0.06921,
          0.068171,
          0.067107,
          0.066019,
          0.064906,
          0.063768,
          0.062604,
          0.061415,
          0.060203,
          0.058967,
          0.057708,
          0.05643,
          0.055132,
          0.053819,
          0.052491,
          0.051152,
          0.049804,
          0.04845,
          0.047093,
          0.045736,
          0.044382,
          0.043034,
          0.041695,
          0.040367,
          0.039053,
          0.037756,
          0.036478,
          0.035221,
          0.033987,
          0.032779,
          0.031599,
          0.030447,
          0.029326,
          0.028237,
          0.027182,
          0.02616,
          0.025174,
          0.024222,
          0.023306,
          0.022426,
          0.021581,
          0.02077,
          0.019994,
          0.019252,
          0.018542,
          0.017864,
          0.017218,
          0.0166,
          0.016012,
          0.015451,
          0.014916,
          0.014407,
          0.013921,
          0.013459,
          0.013019,
          0.012599,
          0.012199,
          0.011819,
          0.011456,
          0.01111,
          0.01078,
          0.010466,
          0.010166,
          0.00988,
          0.009606,
          0.009345,
          0.009096,
          0.008858,
          0.00863,
          0.008412,
          0.008203,
          0.008003,
          0.007812,
          0.007628,
          0.007452,
          0.007283,
          0.007121,
          0.006965,
          0.006815,
          0.006671,
          0.006532,
          0.006399,
          0.00627,
          0.006147,
          0.006027,
          0.005912,
          0.005801,
          0.005694,
          0.00559,
          0.00549,
          0.005393,
          0.005299,
          0.005208,
          0.005121,
          0.005035,
          0.004953,
          0.004873,
          0.004795,
          0.00472,
          0.004647,
          0.004576,
          0.004507,
          0.00444,
          0.004375,
          0.004312,
          0.00425,
          0.004191,
          0.004132,
          0.004075,
          0.00402,
          0.003966,
          0.003913,
          0.003862,
          0.003812,
          0.003763,
          0.003716,
          0.003669,
          0.003624,
          0.00358,
          0.003536,
          0.003494,
          0.003453,
          0.003412,
          0.003372,
          0.003334,
          0.003296,
          0.003259,
          0.003223,
          0.003187,
          0.003152,
          0.003118,
          0.003085,
          0.003052,
          0.00302,
          0.002989,
          0.002958,
          0.002928,
          0.002898,
          0.002869,
          0.00284,
          0.002812,
          0.002785,
          0.002758,
          0.002731,
          0.002705,
          0.00268,
          0.002655,
          0.00263,
          0.002606,
          0.002582,
          0.002559,
          0.002536,
          0.002513,
          0.002491,
          0.002469,
          0.002448,
          0.002426,
          0.002406,
          0.002385,
          0.002365,
          0.002345,
          0.002326,
          0.002307,
          0.002288,
          0.002269,
          0.002251,
          0.002233,
          0.002215,
          0.002197,
          0.00218,
          0.002163,
          0.002146,
          0.00213,
          0.002114,
          0.002098,
          0.002082,
          0.002066,
          0.002051,
          0.002036,
          0.002021,
          0.002006,
          0.001991,
          0.001977,
          0.001963,
          0.001949,
          0.001935,
          0.001922,
          0.001908,
          0.001895,
          0.001882,
          0.001869,
          0.001856,
          0.001844,
          0.001831,
          0.001819,
          0.001807,
          0.001795,
          0.001783,
          0.001772,
          0.00176,
          0.001749,
          0.001738,
          0.001727,
          0.001716,
          0.001705,
          0.001694,
          0.001684,
          0.001673,
          0.001663,
          0.001653,
          0.001643,
          0.001633,
          0.001623,
          0.001613,
          0.001603,
          0.001594,
          0.001584,
          0.001575,
          0.001566,
          0.001557,
          0.001548,
          0.001539,
          0.00153,
          0.001521,
          0.001513,
          0.001504,
          0.001496,
          0.001487,
          0.001479,
          0.001471,
          0.001463,
          0.001455,
          0.001447,
          0.001439,
          0.001431,
          0.001424,
          0.001416,
          0.001409,
          0.001401,
          0.001394,
          0.001386,
          0.001379,
          0.001372,
          0.001365,
          0.001358,
          0.001351,
          0.001344,
          0.001337,
          0.001331,
          0.001324,
          0.001317,
          0.001311,
          0.001304,
          0.001298,
          0.001291,
          0.001285,
          0.001279,
          0.001273,
          0.001266,
          0.00126,
          0.001254,
          0.001248,
          0.001242,
          0.001236,
          0.001231,
          0.001225,
          0.001219,
          0.001214,
          0.001208,
          0.001202,
          0.001197,
          0.001191,
          0.001186,
          0.001181,
          0.001175,
          0.00117,
          0.001165,
          0.001159,
          0.001154,
          0.001149,
          0.001144,
          0.001139,
          0.001134,
          0.001129,
          0.001124,
          0.001119,
          0.001115,
          0.00111,
          0.001105,
          0.0011,
          0.001096,
          0.001091,
          0.001086,
          0.001082,
          0.001077,
          0.001073,
          0.001068,
          0.001064,
          0.00106,
          0.001055,
          0.001051,
          0.001047,
          0.001042,
          0.001038,
          0.001034,
          0.00103,
          0.001026,
          0.001022,
          0.001018,
          0.001014,
          0.00101,
          0.001006,
          0.001002,
          0.000998,
          0.000994,
          0.00099,
          0.000986,
          0.000983,
          0.000979,
          0.000975,
          0.000971,
          0.000968,
          0.000964,
          0.00096
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cost Function"
        },
        "xaxis": {
         "tickformat": "d",
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "title": {
          "text": "Cost"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"97df3aa4-1823-4c04-93e7-e9582065cb76\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"97df3aa4-1823-4c04-93e7-e9582065cb76\")) {                    Plotly.newPlot(                        \"97df3aa4-1823-4c04-93e7-e9582065cb76\",                        [{\"mode\": \"lines+markers\", \"name\": \"Cost\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500], \"y\": [0.144559, 0.141042, 0.135283, 0.129363, 0.125583, 0.125146, 0.127344, 0.130305, 0.132351, 0.132669, 0.131305, 0.128938, 0.126578, 0.125143, 0.125012, 0.125886, 0.127056, 0.127849, 0.127914, 0.12729, 0.12631, 0.125409, 0.124927, 0.124953, 0.125332, 0.125781, 0.126048, 0.126016, 0.125724, 0.125321, 0.124983, 0.124824, 0.124862, 0.12502, 0.125183, 0.125259, 0.125212, 0.125071, 0.1249, 0.124769, 0.124715, 0.124734, 0.124791, 0.124839, 0.124844, 0.1248, 0.124722, 0.12464, 0.12458, 0.124551, 0.124548, 0.124554, 0.12455, 0.124525, 0.124481, 0.124425, 0.12437, 0.124325, 0.124292, 0.124266, 0.124239, 0.124205, 0.124159, 0.124105, 0.124047, 0.123989, 0.123935, 0.123882, 0.123829, 0.123772, 0.123709, 0.123638, 0.123563, 0.123484, 0.123404, 0.123321, 0.123237, 0.123148, 0.123053, 0.122953, 0.122846, 0.122734, 0.122618, 0.122497, 0.122371, 0.12224, 0.122102, 0.121958, 0.121806, 0.121647, 0.121481, 0.121309, 0.121129, 0.120942, 0.120747, 0.120543, 0.120331, 0.120109, 0.119879, 0.119639, 0.11939, 0.119131, 0.118861, 0.118581, 0.118289, 0.117986, 0.117672, 0.117345, 0.117006, 0.116654, 0.116289, 0.11591, 0.115517, 0.11511, 0.114689, 0.114252, 0.1138, 0.113334, 0.112851, 0.112353, 0.111839, 0.111309, 0.110764, 0.110203, 0.109627, 0.109035, 0.10843, 0.107809, 0.107175, 0.106528, 0.105869, 0.105198, 0.104516, 0.103824, 0.103123, 0.102413, 0.101696, 0.100972, 0.100242, 0.099507, 0.098767, 0.098023, 0.097275, 0.096525, 0.095772, 0.095017, 0.09426, 0.0935, 0.09274, 0.091977, 0.091213, 0.090447, 0.08968, 0.08891, 0.088138, 0.087363, 0.086585, 0.085803, 0.085018, 0.084228, 0.083432, 0.082631, 0.081822, 0.081007, 0.080182, 0.079348, 0.078503, 0.077646, 0.076777, 0.075893, 0.074994, 0.074079, 0.073145, 0.072193, 0.07122, 0.070226, 0.06921, 0.068171, 0.067107, 0.066019, 0.064906, 0.063768, 0.062604, 0.061415, 0.060203, 0.058967, 0.057708, 0.05643, 0.055132, 0.053819, 0.052491, 0.051152, 0.049804, 0.04845, 0.047093, 0.045736, 0.044382, 0.043034, 0.041695, 0.040367, 0.039053, 0.037756, 0.036478, 0.035221, 0.033987, 0.032779, 0.031599, 0.030447, 0.029326, 0.028237, 0.027182, 0.02616, 0.025174, 0.024222, 0.023306, 0.022426, 0.021581, 0.02077, 0.019994, 0.019252, 0.018542, 0.017864, 0.017218, 0.0166, 0.016012, 0.015451, 0.014916, 0.014407, 0.013921, 0.013459, 0.013019, 0.012599, 0.012199, 0.011819, 0.011456, 0.01111, 0.01078, 0.010466, 0.010166, 0.00988, 0.009606, 0.009345, 0.009096, 0.008858, 0.00863, 0.008412, 0.008203, 0.008003, 0.007812, 0.007628, 0.007452, 0.007283, 0.007121, 0.006965, 0.006815, 0.006671, 0.006532, 0.006399, 0.00627, 0.006147, 0.006027, 0.005912, 0.005801, 0.005694, 0.00559, 0.00549, 0.005393, 0.005299, 0.005208, 0.005121, 0.005035, 0.004953, 0.004873, 0.004795, 0.00472, 0.004647, 0.004576, 0.004507, 0.00444, 0.004375, 0.004312, 0.00425, 0.004191, 0.004132, 0.004075, 0.00402, 0.003966, 0.003913, 0.003862, 0.003812, 0.003763, 0.003716, 0.003669, 0.003624, 0.00358, 0.003536, 0.003494, 0.003453, 0.003412, 0.003372, 0.003334, 0.003296, 0.003259, 0.003223, 0.003187, 0.003152, 0.003118, 0.003085, 0.003052, 0.00302, 0.002989, 0.002958, 0.002928, 0.002898, 0.002869, 0.00284, 0.002812, 0.002785, 0.002758, 0.002731, 0.002705, 0.00268, 0.002655, 0.00263, 0.002606, 0.002582, 0.002559, 0.002536, 0.002513, 0.002491, 0.002469, 0.002448, 0.002426, 0.002406, 0.002385, 0.002365, 0.002345, 0.002326, 0.002307, 0.002288, 0.002269, 0.002251, 0.002233, 0.002215, 0.002197, 0.00218, 0.002163, 0.002146, 0.00213, 0.002114, 0.002098, 0.002082, 0.002066, 0.002051, 0.002036, 0.002021, 0.002006, 0.001991, 0.001977, 0.001963, 0.001949, 0.001935, 0.001922, 0.001908, 0.001895, 0.001882, 0.001869, 0.001856, 0.001844, 0.001831, 0.001819, 0.001807, 0.001795, 0.001783, 0.001772, 0.00176, 0.001749, 0.001738, 0.001727, 0.001716, 0.001705, 0.001694, 0.001684, 0.001673, 0.001663, 0.001653, 0.001643, 0.001633, 0.001623, 0.001613, 0.001603, 0.001594, 0.001584, 0.001575, 0.001566, 0.001557, 0.001548, 0.001539, 0.00153, 0.001521, 0.001513, 0.001504, 0.001496, 0.001487, 0.001479, 0.001471, 0.001463, 0.001455, 0.001447, 0.001439, 0.001431, 0.001424, 0.001416, 0.001409, 0.001401, 0.001394, 0.001386, 0.001379, 0.001372, 0.001365, 0.001358, 0.001351, 0.001344, 0.001337, 0.001331, 0.001324, 0.001317, 0.001311, 0.001304, 0.001298, 0.001291, 0.001285, 0.001279, 0.001273, 0.001266, 0.00126, 0.001254, 0.001248, 0.001242, 0.001236, 0.001231, 0.001225, 0.001219, 0.001214, 0.001208, 0.001202, 0.001197, 0.001191, 0.001186, 0.001181, 0.001175, 0.00117, 0.001165, 0.001159, 0.001154, 0.001149, 0.001144, 0.001139, 0.001134, 0.001129, 0.001124, 0.001119, 0.001115, 0.00111, 0.001105, 0.0011, 0.001096, 0.001091, 0.001086, 0.001082, 0.001077, 0.001073, 0.001068, 0.001064, 0.00106, 0.001055, 0.001051, 0.001047, 0.001042, 0.001038, 0.001034, 0.00103, 0.001026, 0.001022, 0.001018, 0.001014, 0.00101, 0.001006, 0.001002, 0.000998, 0.000994, 0.00099, 0.000986, 0.000983, 0.000979, 0.000975, 0.000971, 0.000968, 0.000964, 0.00096]}],                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Cost Function\"}, \"xaxis\": {\"tickformat\": \"d\", \"title\": {\"text\": \"Epochs\"}}, \"yaxis\": {\"title\": {\"text\": \"Cost\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('97df3aa4-1823-4c04-93e7-e9582065cb76');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "\n",
      "Predicted Value:\n",
      "[[0.04949508]\n",
      " [0.95872866]\n",
      " [0.95861363]\n",
      " [0.04228754]]\n",
      "\n",
      "Actual Output:\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "model = network.Sequential()\n",
    "model.add_layer(layer.Dense(n_neurons=3, name='Layer_1', optimiser=optimiser.SGDM(lr=1, freeze_weights=False, momentum=0.9), weights=np.array([[0.1, 0.2, 0.3],\n",
    "                                                                                                                             [0.6, 0.4, 0.7]]),\n",
    "                                bias=np.array([[0, 0, 0]])))\n",
    "\n",
    "model.add_layer(activation.Sigmoid(name='Activation_1'))\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=1, name='Layer_2', optimiser=optimiser.SGDM(lr=1, freeze_weights=False, momentum=0.9), weights=np.array([[0.1],\n",
    "                                                                                                                                 [0.4],\n",
    "                                                                                                                                 [0.9]]),\n",
    "                                bias = np.array([[0]])))\n",
    "\n",
    "model.add_layer(activation.Sigmoid(name='Activation_2'))\n",
    "\n",
    "model.compile(loss=loss.MSE(), inputs=X, target=Y, batch=4)\n",
    "print(model)\n",
    "\n",
    "model.train(epochs=500)\n",
    "\n",
    "pred_val = model.predict(inputs=X)\n",
    "print(f'Input:\\n{X}', end='\\n'*2)\n",
    "print(f'Predicted Value:\\n{pred_val}', end='\\n'*2)\n",
    "print(f'Actual Output:\\n{Y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.1446\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 988us/step - loss: 0.1410\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1353\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1294\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1256\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1251\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1273\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1303\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1324\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1327\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1313\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1289\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1266\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1251\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1250\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1259\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1271\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1278\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1279\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1273\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1263\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1254\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1249\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1250\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1253\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1258\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1260\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1260\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1257\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1253\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1250\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1248\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1249\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.1250\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.1252\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1253\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1252\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1251\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1249\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1248\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1247\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1247\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1248\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1248\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1248\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1248\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1247\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1246\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1246\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.1246\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.1245\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1246\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1245\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.1245\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1245\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1244\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1244\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1243\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1243\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1243\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1242\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.1242\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1242\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1241\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1240\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1240\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1239\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1239\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1238\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1238\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1237\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1236\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1236\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1235\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1234\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1233\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1232\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1231\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1231\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1230\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1228\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.1227\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1226\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1225\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1224\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1222\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1221\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1220\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1218\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1216\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1215\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1213\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1211\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1209\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1207\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.1205\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1203\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1201\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1199\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1196\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1194\n",
      "Epoch 102/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 0.1191\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1189\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1186\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.1183\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1180\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.1177\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1173\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.1170\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1167\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1163\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1159\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1155\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1151\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1147\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1143\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1138\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1133\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1129\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1124\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1118\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 990us/step - loss: 0.1113\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1108\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1102\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1096\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.1090\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1084\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1078\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1072\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 989us/step - loss: 0.1065\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1059\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.1052\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1045\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.1038\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1031\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1024\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1017\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1010\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.1002\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0995\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0988\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.0980\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0973\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0965\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0958\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.0950\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0943\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0935\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0927\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0920\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0912\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0904\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0897\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0889\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0881\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0874\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0866\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0858\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0850\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0842\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0834\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0826\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0818\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0810\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0802\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0793\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0785\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0776\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0768\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0759\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0750\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0741\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.0731\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0722\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0712\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0702\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0692\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0682\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0671\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0660\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0649\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0638\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0626\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0614\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0602\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0590\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0577\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0564\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0551\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0538\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0525\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0512\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0498\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0484\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0471\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0457\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0444\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0430\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0417\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0404\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0391\n",
      "Epoch 202/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 0.0378\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0365\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0352\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0340\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.0328\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0316\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0304\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0293\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0282\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0272\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0262\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0252\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0242\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0233\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0224\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0216\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0208\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0200\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0193\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0185\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0179\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0172\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0166\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0160\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.0155\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0149\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0144\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0135\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0130\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0126\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0122\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0118\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0115\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0111\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.0108\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0105\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0102\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0099\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.0096\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0093\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0091\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0086\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0084\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 987us/step - loss: 0.0082\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.0080\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0078\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0076\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0075\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0073\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0071\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0070\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0068\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0067\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0065\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0064\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0063\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0061\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0060\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 989us/step - loss: 0.0059\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0058\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0057\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0056\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0055\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0054\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0053\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0052\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0051\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0050\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0049\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0048\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0047\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0046\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0046\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0045\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.0044\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0044\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0043\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0043\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0042\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0041\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0041\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0040\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0040\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0039\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0039\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0038\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0038\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0037\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0036\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0036\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0035\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0035\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0035\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0034\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0034\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0033\n",
      "Epoch 302/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 0.0033\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0033\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0032\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0032\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0032\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0031\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0030\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0030\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0030\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0029\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0029\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0029\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0028\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0028\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0028\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 966us/step - loss: 0.0028\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0027\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0027\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0027\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.0027\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0026\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0026\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0026\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0026\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.0025\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0025\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0025\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0024\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.0024\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0023\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0023\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0023\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.0023\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0023\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0022\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0022\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0021\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0021\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0021\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0021\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0021\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0020\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0020\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0020\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0019\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0019\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0019\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0019\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0018\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0018\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0018\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0018\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0018\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0018\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0017\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0017\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0017\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0017\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0017\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0017\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0016\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0016\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0016\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0016\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0016\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0016\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0016\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0016\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0015\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0015\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0015\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0015\n",
      "Epoch 402/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 998us/step - loss: 0.0015\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.0015\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0015\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0015\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0015\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0015\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0015\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0014\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0014\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0014\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0014\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0014\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0014\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0014\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0014\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0014\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0014\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0014\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0014\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0014\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0014\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0013\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.0013\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0013\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0013\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0013\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0013\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0013\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0013\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0013\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0013\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0013\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0013\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0012\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0012\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0012\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0012\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0012\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0012\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0012\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0012\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0012\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0011\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0011\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0011\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0011\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0011\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0011\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0011\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0011\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0011\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0011\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0011\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0011\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0011\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0011\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0011\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0011\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0011\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0011\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0011\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0010\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0010\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0010\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0010\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0010\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0010\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0010\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0010\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 9.9788e-04\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 9.9401e-04\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9016e-04\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8634e-04\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.8255e-04\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 9.7879e-04\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 9.7505e-04\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 993us/step - loss: 9.7134e-04\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6766e-04\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.6400e-04\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 9.6037e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ac1cd6c220>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def custom_mse(y_true, y_pred):\n",
    "    loss = K.square(y_pred - y_true)\n",
    "    loss = loss * (1/8)\n",
    "    loss = K.sum(loss, axis=0)\n",
    "    return loss\n",
    "\n",
    "X = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]], dtype=np.float)\n",
    "\n",
    "Y = np.array([[0], [1], [1], [0]], dtype=np.float)\n",
    "\n",
    "model_keras = Sequential()\n",
    "model_keras.add(Dense(units=3, activation='sigmoid', input_shape=(2,), name='first'))\n",
    "model_keras.add(Dense(units=1, activation='sigmoid', name='second'))\n",
    "\n",
    "model_keras.layers[0].set_weights([np.array([[0.1, 0.2, 0.3],\n",
    "                                              [0.6, 0.4, 0.7]]),\n",
    "                                   np.array([[0, 0, 0]]).reshape(-1)])\n",
    "\n",
    "model_keras.layers[1].set_weights([np.array([[0.1],\n",
    "                                             [0.4],\n",
    "                                             [0.9]]),\n",
    "                                   np.array([[0]]).reshape(-1)])\n",
    "\n",
    "model_keras.compile(loss=custom_mse,\n",
    "                    optimizer=optimizers.SGD(learning_rate=1, momentum=0.9, nesterov=False)\n",
    "                    )\n",
    "\n",
    "model_keras.fit(X, Y.reshape(-1), epochs=500, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.12930797 2.09429725 6.19536018]\n",
      " [3.17463709 2.05136235 6.21631593]]\n",
      "[[-4.92289571 -3.3036427  -2.75736248]]\n",
      "\n",
      "[array([[3.129308 , 2.0942974, 6.195357 ],\n",
      "       [3.1746373, 2.0513628, 6.216316 ]], dtype=float32), array([-4.922894, -3.303642, -2.757363], dtype=float32)]\n",
      "\n",
      "[[-6.63531287]\n",
      " [-4.63932827]\n",
      " [ 8.68663435]]\n",
      "[[-3.26107981]]\n",
      "\n",
      "[array([[-6.63531  ],\n",
      "       [-4.6393294],\n",
      "       [ 8.686637 ]], dtype=float32), array([-3.2610788], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].weights)\n",
    "print(model.layers[0].bias)\n",
    "\n",
    "print()\n",
    "\n",
    "print(model_keras.layers[0].get_weights())\n",
    "\n",
    "print()\n",
    "\n",
    "print(model.layers[2].weights)\n",
    "print(model.layers[2].bias)\n",
    "\n",
    "print()\n",
    "\n",
    "print(model_keras.layers[1].get_weights())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantile Regression\n",
    "## Modelling Interval For Noisy Sine Wave\n",
    "Prediction Interval at 0.977 - 0.023 ~ 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_predictable(x):\n",
    "    return x+np.sin(np.pi*x/2)\n",
    "\n",
    "\n",
    "def f(x, std=0.2):\n",
    "    return f_predictable(x)+np.random.randn(len(x))*std\n",
    "\n",
    "\n",
    "def get_data(num, start=0, end=4):\n",
    "        x = np.sort(np.random.rand(num)*(end-start)+start)\n",
    "        y = f(x)\n",
    "        return x.reshape(-1, 1), y\n",
    "\n",
    "x_train, y_train = get_data(num=20000)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "x_test, y_test = get_data(num=1000)\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x_train.reshape(-1), y=y_train.reshape(-1),\n",
    "                    mode='markers',\n",
    "                    name='Original Data'))\n",
    "fig.update_layout(title='Noisy Sine Wave')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_upper = network.Sequential()\n",
    "\n",
    "model_upper.add_layer(layer.Dense(n_neurons=100, name='Layer_1', optimiser=optimiser.SGD(), freeze_weights=False, lr=0.01))\n",
    "\n",
    "model_upper.add_layer(activation.ReLU(name='Activation_1'))\n",
    "\n",
    "model_upper.add_layer(layer.Dense(n_neurons=100, name='Layer_2', optimiser=optimiser.SGD(), freeze_weights=False, lr=0.01))\n",
    "\n",
    "model_upper.add_layer(activation.ReLU(name='Activation_2'))\n",
    "\n",
    "model_upper.add_layer(layer.Dense(n_neurons=100, name='Layer_3', optimiser=optimiser.SGD(), freeze_weights=False, lr=0.01))\n",
    "\n",
    "model_upper.add_layer(activation.ReLU(name='Activation_3'))\n",
    "\n",
    "model_upper.add_layer(layer.Dense(n_neurons=1, name='Layer_4', optimiser=optimiser.SGD(), freeze_weights=False, lr=0.01))\n",
    "\n",
    "model_upper.compile(loss=loss.Quantile(quantile=0.977), inputs=x_train, target=y_train, batch=24)\n",
    "\n",
    "model_upper.train(epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lower = network.Sequential()\n",
    "\n",
    "model_lower.add_layer(layer.Dense(n_neurons=100, name='Layer_1', optimiser=optimiser.SGD(), freeze_weights=False, lr=0.01))\n",
    "\n",
    "model_lower.add_layer(activation.ReLU(name='Activation_1'))\n",
    "\n",
    "model_lower.add_layer(layer.Dense(n_neurons=100, name='Layer_2', optimiser=optimiser.SGD(), freeze_weights=False, lr=0.01))\n",
    "\n",
    "model_lower.add_layer(activation.ReLU(name='Activation_2'))\n",
    "\n",
    "model_lower.add_layer(layer.Dense(n_neurons=100, name='Layer_3', optimiser=optimiser.SGD(), freeze_weights=False, lr=0.01))\n",
    "\n",
    "model_lower.add_layer(activation.ReLU(name='Activation_3'))\n",
    "\n",
    "model_lower.add_layer(layer.Dense(n_neurons=1, name='Layer_4', optimiser=optimiser.SGD(), freeze_weights=False, lr=0.01))\n",
    "\n",
    "model_lower.compile(loss=loss.Quantile(quantile=0.023), inputs=x_train, target=y_train, batch=24)\n",
    "\n",
    "model_lower.train(epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x_train.reshape(-1), y=y_train.reshape(-1),\n",
    "                    mode='markers',\n",
    "                    name='Original Data'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x_test.reshape(-1), y=model_upper.predict(x_test).reshape(-1),\n",
    "                    mode='lines',\n",
    "                    name='Upper Bound'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x_test.reshape(-1), y=model_lower.predict(x_test).reshape(-1),\n",
    "                    mode='lines',\n",
    "                    name='Lower Bound'))\n",
    "\n",
    "fig.update_layout(title='Noisy Sine Wave With 95% Prediction Bounds')\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification\n",
    "Modelling Multi Class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "cat_images = np.random.randn(700, 2) + np.array([0, -3])\n",
    "mouse_images = np.random.randn(700, 2) + np.array([3, 3])\n",
    "dog_images = np.random.randn(700, 2) + np.array([-3, 3])\n",
    "\n",
    "feature_set = np.vstack([cat_images, mouse_images, dog_images])\n",
    "labels = np.array([0]*700 + [1]*700 + [2]*700)\n",
    "\n",
    "one_hot_labels = np.zeros((2100, 3))\n",
    "\n",
    "for i in range(2100):\n",
    "    one_hot_labels[i, labels[i]] = 1\n",
    "    \n",
    "dataset = pd.DataFrame(np.hstack([feature_set, labels.reshape(-1, 1)]), columns=['X','Y','Labels'])\n",
    "dataset.Labels = dataset.Labels.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(dataset, x=\"X\", y=\"Y\", color=\"Labels\", hover_data=[dataset.index])\n",
    "fig.update_layout(width=1000, height=800, title='Various Images Data Distribution')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = network.Sequential()\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=4, name='Layer_1', optimiser=optimiser.SGD(), freeze_weights=False, lr=0.001))\n",
    "\n",
    "model.add_layer(activation.Sigmoid(name='Activation_1'))\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=3, name='Layer_2', optimiser=optimiser.SGD(), freeze_weights=False, lr=0.001))\n",
    "\n",
    "model.add_layer(activation.Sigmoid(name='Activation_2'))\n",
    "\n",
    "model.compile(loss=loss.CrossEntropy(), inputs=feature_set, target=one_hot_labels, batch=16)\n",
    "\n",
    "model.train(epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = np.argmax(model.predict(feature_set), axis=1)\n",
    "np.where((pred_val == labels)==False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SquaredHinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = -1*np.ones((2100, 3))\n",
    "\n",
    "for i in range(2100):\n",
    "    one_hot_labels[i, labels[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = network.Sequential()\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=4, name='Layer_1', optimiser=optimiser.SGD(), freeze_weights=False, lr=0.001))\n",
    "\n",
    "model.add_layer(activation.Sigmoid(name='Activation_1'))\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=3, name='Layer_2', optimiser=optimiser.SGD(), freeze_weights=False, lr=0.001))\n",
    "\n",
    "model.add_layer(activation.Tanh(name='Activation_2'))\n",
    "\n",
    "model.compile(loss=loss.SquaredHinge(), inputs=feature_set, target=one_hot_labels, batch=16)\n",
    "\n",
    "model.train(epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = np.argmax(model.predict(feature_set), axis=1)\n",
    "np.where((pred_val == labels)==False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification\n",
    "Modelling Multi Label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "cat_images = np.random.randn(700, 2) + np.array([0, -3])\n",
    "mouse_images = np.random.randn(700, 2) + np.array([3, 3])\n",
    "dog_images = np.random.randn(700, 2) + np.array([-3, 3])\n",
    "\n",
    "feature_set = np.vstack([cat_images, mouse_images, dog_images])\n",
    "labels = np.array([0]*700 + [1]*700 + [1]*700)\n",
    "\n",
    "one_hot_labels = np.zeros((2100, 3))\n",
    "\n",
    "for i in range(700):\n",
    "    one_hot_labels[i, labels[i]] = 1\n",
    "    \n",
    "for i in range(700, 2100):\n",
    "    one_hot_labels[i,1:] = 1\n",
    "    \n",
    "dataset = pd.DataFrame(np.hstack([feature_set, labels.reshape(-1, 1)]), columns=['X','Y','Labels'])\n",
    "dataset.Labels = dataset.Labels.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(dataset, x=\"X\", y=\"Y\", color=\"Labels\", hover_data=[dataset.index])\n",
    "fig.update_layout(width=1000, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network.Sequential()\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=4, name='Layer_1', optimiser=optimiser.SGD(), freeze_weights=False, lr=0.001))\n",
    "\n",
    "model.add_layer(activation.Sigmoid(name='Activation_1'))\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=3, name='Layer_2', optimiser=optimiser.SGD(), freeze_weights=False, lr=0.001))\n",
    "\n",
    "model.add_layer(activation.Sigmoid(name='Activation_2'))\n",
    "\n",
    "model.compile(loss=loss.CrossEntropy(), inputs=feature_set, target=one_hot_labels, batch=16)\n",
    "\n",
    "model.train(epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_val = np.where(model.predict(feature_set)>0.5, 1, 0)\n",
    "np.where((pred_val == one_hot_labels)==False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SquaredHinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = -np.ones((2100, 3))\n",
    "\n",
    "for i in range(700):\n",
    "    one_hot_labels[i, labels[i]] = 1\n",
    "    \n",
    "for i in range(700, 2100):\n",
    "    one_hot_labels[i,1:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network.Sequential()\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=4, name='Layer_1', optimiser=optimiser.SGD(), freeze_weights=False, lr=0.001))\n",
    "\n",
    "model.add_layer(activation.Sigmoid(name='Activation_1'))\n",
    "\n",
    "model.add_layer(layer.Dense(n_neurons=3, name='Layer_2', optimiser=optimiser.SGD(), freeze_weights=False, lr=0.001))\n",
    "\n",
    "model.add_layer(activation.Tanh(name='Activation_2'))\n",
    "\n",
    "model.compile(loss=loss.SquaredHinge(), inputs=feature_set, target=one_hot_labels, batch=16)\n",
    "\n",
    "model.train(epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = np.where(model.predict(feature_set)>0, 1, -1)\n",
    "np.where((pred_val == one_hot_labels)==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
